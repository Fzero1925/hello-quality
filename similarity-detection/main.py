#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Similarity Detection Tool - Main Entry Point

Modularized similarity detection system for content deduplication.
Maintains compatibility with the original similarity_checker.py interface.
"""

import os
import sys
import argparse
import codecs
from pathlib import Path
from typing import Optional

# Resolve Windows encoding issues
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Add current directory to path
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# Import modular components
try:
    from core.similarity_engine import SimilarityEngine
    from reporters.markdown_reporter import MarkdownReporter
    from reporters.simple_reporter import SimpleReporter
    from reporters.seo_config_generator import SEOConfigGenerator
except ImportError as e:
    print(f"âš ï¸ æ¨¡å—å¯¼å…¥è­¦å‘Š: {e}")
    print("   è¯·ç¡®ä¿åœ¨similarity-detectionç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def main():
    """Main function with full CLI compatibility."""
    parser = argparse.ArgumentParser(description='æ¨¡å—åŒ–æ–‡ç« ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·')
    parser.add_argument('directory', nargs='?', help='è¦æ£€æµ‹çš„æ–‡ç« ç›®å½•è·¯å¾„')
    parser.add_argument('--config', default='../config/uniqueness.yml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--threshold', type=float, help='ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0)')
    parser.add_argument('--output', default='similarity_report.md', help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--auto-process', action='store_true',
                       help='è‡ªåŠ¨ç§»åŠ¨é‡å¤æ–‡ç« åˆ°duplicate_articlesæ–‡ä»¶å¤¹')
    parser.add_argument('--dry-run', action='store_true',
                       help='åªæ£€æµ‹ä¸ç§»åŠ¨æ–‡ä»¶ï¼ˆé¢„è§ˆæ¨¡å¼ï¼‰')
    parser.add_argument('--window-days', type=int,
                       help='æ£€æµ‹æ—¶é—´çª—å£ï¼ˆå¤©æ•°ï¼‰')
    parser.add_argument('--compare', nargs=2, metavar=('FILE1', 'FILE2'),
                       help='å¯¹æ¯”ä¸¤ç¯‡æŒ‡å®šæ–‡ç« çš„ç›¸ä¼¼åº¦')
    parser.add_argument('--debug', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†çš„æ¯”è¾ƒè¿‡ç¨‹å’Œè°ƒè¯•ä¿¡æ¯')
    parser.add_argument('--algorithm', choices=['linear', 'graph'], default='linear',
                       help='é€‰æ‹©æ£€æµ‹ç®—æ³•: linear(çº¿æ€§,é»˜è®¤) æˆ– graph(å…¨è¿æ¥å›¾)')
    parser.add_argument('--generate-config', action='store_true',
                       help='ç”ŸæˆSEOä¼˜åŒ–é…ç½®æ–‡ä»¶ (redirects.yaml, canonical_mappings.jsonç­‰)')
    parser.add_argument('--config-output-dir', default='.',
                       help='é…ç½®æ–‡ä»¶è¾“å‡ºç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)')
    parser.add_argument('--simple', action='store_true',
                       help='ç®€åŒ–æ¨¡å¼ï¼šè¾“å‡ºç²¾ç®€çš„ç»“æœæ‘˜è¦ï¼Œé€‚åˆå¿«é€Ÿæ£€æŸ¥')

    args = parser.parse_args()

    if args.simple:
        print("ğŸš€ ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…· (ç®€åŒ–æ¨¡å¼)")
    else:
        print("ğŸš€ æ¨¡å—åŒ–æ–‡ç« ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·")
        print("=" * 50)

    # Handle compare mode
    if args.compare:
        file1, file2 = args.compare
        print(f"ğŸ” å¯¹æ¯”æ¨¡å¼å¯åŠ¨")

        # Initialize engine
        engine = SimilarityEngine(args.config)

        # Set debug mode
        if args.debug:
            engine.set_debug_mode(True)
            print("ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")

        # Execute comparison
        result = engine.compare_two_articles(file1, file2)

        if result:
            print("\nâœ… å¯¹æ¯”å®Œæˆ")
        else:
            print("\nâŒ å¯¹æ¯”å¤±è´¥")
            return 1

        return 0

    # Check directory
    if not args.directory:
        print(f"âŒ è¯·æŒ‡å®šè¦æ£€æµ‹çš„ç›®å½•è·¯å¾„")
        return 1

    if not Path(args.directory).exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.directory}")
        return 1

    try:
        # Initialize engine
        engine = SimilarityEngine(args.config)

        # Set debug mode
        if args.debug:
            engine.set_debug_mode(True)
            print("ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")

        # Override configuration parameters
        if args.threshold:
            engine.similarity_threshold = args.threshold
            print(f"ğŸ“Š ä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼: {args.threshold}")

        if args.window_days:
            engine.comparison_window_days = args.window_days
            print(f"â° ä½¿ç”¨è‡ªå®šä¹‰æ—¶é—´çª—å£: {args.window_days} å¤©")

        # 1. Scan articles
        if args.simple:
            print(f"ğŸ“ æ‰«æ: {args.directory}")
        else:
            print(f"\nğŸ“ æ‰«æç›®å½•: {args.directory}")

        articles = engine.scan_articles(args.directory)

        if not articles:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯åˆ†æçš„æ–‡ç« ")
            return 1

        # 2. Similarity detection (based on algorithm choice)
        if args.algorithm == 'graph':
            if args.simple:
                print(f"ğŸ” æ£€æµ‹ç›¸ä¼¼åº¦...")
            else:
                print(f"\nğŸ” å¼€å§‹å…¨è¿æ¥å›¾ç›¸ä¼¼åº¦æ£€æµ‹...")
            detection_result = engine.detect_duplicate_groups(articles)
        else:
            if args.simple:
                print(f"ğŸ” æ£€æµ‹ç›¸ä¼¼åº¦...")
            else:
                print(f"\nğŸ” å¼€å§‹çº¿æ€§ç›¸ä¼¼åº¦æ£€æµ‹...")
            detection_result = engine.detect_similarities_linear(articles)

        # 3. Process articles classification (optional)
        if args.auto_process and detection_result.get('moved_articles'):
            print(f"\nğŸ”„ è‡ªåŠ¨å¤„ç†ç›¸ä¼¼æ–‡ç« ...")
            move_files = not args.dry_run
            if args.dry_run:
                print("âš ï¸ é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºæ“ä½œï¼Œä¸å®é™…ç§»åŠ¨æ–‡ä»¶")

            process_result = engine.process_articles_by_date(detection_result, move_files)

            if move_files:
                print(f"\nâœ… è‡ªåŠ¨å¤„ç†å®Œæˆ:")
                print(f"  âœ… ä¿ç•™æ–‡ç« : {process_result['kept_count']} ç¯‡")
                print(f"  ğŸ“¦ ç§»åŠ¨æ–‡ç« : {process_result['moved_count']} ç¯‡")
                print(f"  ğŸ“ ä¿ç•™æ–‡ç« ç›®å½•: {process_result['new_articles_folder']}")
                print(f"  ğŸ“ ç›¸ä¼¼æ–‡ç« ç›®å½•: {process_result['old_articles_folder']}")
            else:
                print(f"\nğŸ“‹ é¢„è§ˆç»“æœ:")
                print(f"  âœ… å°†ä¿ç•™: {process_result['kept_count']} ç¯‡æ–‡ç« ")
                print(f"  ğŸ“¦ å°†ç§»åŠ¨: {process_result['moved_count']} ç¯‡æ–‡ç« ")

        # 4. Generate reports and display summary
        if not args.simple:
            print(f"\n" + "=" * 50)

        # Initialize reporters
        markdown_reporter = MarkdownReporter(engine.config)
        simple_reporter = SimpleReporter(engine.config)
        seo_generator = SEOConfigGenerator(engine.config)

        if args.algorithm == 'graph':
            duplicate_groups = detection_result.get('duplicate_groups', [])
            unique_articles = detection_result.get('unique_articles', [])
            total_duplicates = sum(len(group['articles']) for group in duplicate_groups)

            if args.simple:
                # Simplified mode output
                print(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼")
                if duplicate_groups:
                    print(f"âš ï¸  å‘ç°é—®é¢˜: {len(duplicate_groups)} ä¸ªé‡å¤ç¾¤ç»„ï¼Œ{total_duplicates} ç¯‡é‡å¤æ–‡ç« ")
                else:
                    print(f"âœ… æœªå‘ç°é‡å¤å†…å®¹ï¼{len(unique_articles)} ç¯‡æ–‡ç« éƒ½æ˜¯ç‹¬ç«‹åŸåˆ›")
            else:
                # Detailed mode output
                print(f"ğŸ‰ å…¨è¿æ¥å›¾æ£€æµ‹å®Œæˆï¼")
                print(f"ğŸ“Š æ£€æµ‹äº† {len(articles)} ç¯‡æ–‡ç« ")
                print(f"ğŸ“Š æ€»æ¯”è¾ƒæ¬¡æ•°: {detection_result['total_comparisons']}")
                print(f"ğŸ“¦ å‘ç°é‡å¤ç¾¤ç»„: {len(duplicate_groups)} ä¸ª")
                print(f"ğŸ”¸ é‡å¤æ–‡ç« æ€»æ•°: {total_duplicates} ç¯‡")
                print(f"âœ… ç‹¬ç«‹æ–‡ç« : {len(unique_articles)} ç¯‡")

            # Generate reports (based on mode selection)
            if args.simple:
                print(f"\nğŸ“„ ç”Ÿæˆç®€åŒ–æŠ¥å‘Š...")
                report_file = args.output.replace('.md', '_simple.md')
                simple_reporter.generate_simple_report(detection_result, report_file)
            else:
                print(f"\nğŸ“„ ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š...")
                report_file = args.output.replace('.md', '_graph_analysis.md')
                markdown_reporter.generate_duplicate_analysis_report(detection_result, report_file)

            # Generate SEO config files (optional)
            if args.generate_config and duplicate_groups:
                print(f"\nğŸ“ ç”ŸæˆSEOä¼˜åŒ–é…ç½®æ–‡ä»¶...")
                config_files = seo_generator.generate_seo_config_files(detection_result, args.config_output_dir)
                if config_files:
                    print(f"ğŸ“Š é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ:")
                    for config_type, file_path in config_files.items():
                        print(f"  âœ… {config_type}: {file_path}")
                else:
                    print("âš ï¸ æœªå‘ç°éœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶çš„é‡å¤ç¾¤ç»„")
            elif args.generate_config:
                print("â„¹ï¸ æœªå‘ç°é‡å¤ç¾¤ç»„ï¼Œè·³è¿‡é…ç½®æ–‡ä»¶ç”Ÿæˆ")

        else:
            # Linear algorithm results
            print(f"ğŸ‰ çº¿æ€§æ£€æµ‹å®Œæˆï¼")
            print(f"ğŸ“Š æ£€æµ‹äº† {len(articles)} ç¯‡æ–‡ç« ")
            print(f"ğŸ“Š æ€»æ¯”è¾ƒæ¬¡æ•°: {detection_result['total_comparisons']}")
            print(f"âœ… ä¿ç•™æ–‡ç« : {len(detection_result['kept_articles'])} ç¯‡")
            print(f"ğŸ“¦ ç›¸ä¼¼æ–‡ç« : {len(detection_result['moved_articles'])} ç¯‡")

            if not args.auto_process and detection_result['moved_articles']:
                print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨ --auto-process å‚æ•°å¯è‡ªåŠ¨ç§»åŠ¨ç›¸ä¼¼æ–‡ç« ")
                print(f"     ä½¿ç”¨ --dry-run å‚æ•°å¯é¢„è§ˆæ“ä½œè€Œä¸å®é™…ç§»åŠ¨æ–‡ä»¶")

        return 0

    except Exception as e:
        print(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())