#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­æ–‡æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆè¯¦ç»†çš„ä¸­æ–‡è´¨é‡æ£€æµ‹æŠ¥å‘Šï¼ŒåŒ…å«ä¿®å¤å»ºè®®å’Œå›ºå®šçš„å›¾ç‰‡ä¼˜åŒ–è¯´æ˜
"""

import yaml
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import re

class ChineseReporter:
    """ä¸­æ–‡è´¨é‡æ£€æµ‹æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, config_path: str = "hugo_quality_standards.yml"):
        """åˆå§‹åŒ–"""
        self.config = self._load_config(config_path)
        self.report_config = self.config.get('report_settings', {})

    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f) or {}
        except Exception:
            return {}

    def generate_report(self,
                       file_path: str,
                       quality_scores: Dict,
                       hugo_fix_results: Dict,
                       issues: List[Dict],
                       article_stats: Dict,
                       similarity_results: Optional[Dict] = None,
                       alt_analysis_results: Optional[Dict] = None) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ä¸­æ–‡è´¨é‡æ£€æµ‹æŠ¥å‘Š

        Args:
            file_path: æ–‡ç« æ–‡ä»¶è·¯å¾„
            quality_scores: è´¨é‡è¯„åˆ†ç»“æœ
            hugo_fix_results: Hugoæ¨¡æ¿ä¿®å¤ç»“æœ
            issues: å‘ç°çš„é—®é¢˜åˆ—è¡¨
            article_stats: æ–‡ç« ç»Ÿè®¡ä¿¡æ¯
            similarity_results: ç›¸ä¼¼åº¦æ£€æµ‹ç»“æœ
            alt_analysis_results: Altæ–‡æœ¬åˆ†æç»“æœ

        Returns:
            å®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Š
        """
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        file_name = Path(file_path).name if file_path else "æœªçŸ¥æ–‡ç« "

        report_parts = []

        # 1. æŠ¥å‘Šæ ‡é¢˜
        report_parts.append(self._generate_header(file_name, timestamp, file_path))

        # 2. æ£€æŸ¥æ€»ç»“
        report_parts.append(self._generate_summary(quality_scores, hugo_fix_results, issues, article_stats))

        # 3. Hugoæ¨¡æ¿è‡ªåŠ¨ä¿®å¤ç»“æœ
        report_parts.append(self._generate_hugo_fix_section(hugo_fix_results))

        # 4. å›¾ç‰‡ä¼˜åŒ–è¯´æ˜ï¼ˆå¼•ç”¨ç‹¬ç«‹æ–‡æ¡£ï¼‰
        report_parts.append(self._generate_image_reference_section())

        # 5. å…·ä½“é—®é¢˜åˆ†æ
        report_parts.append(self._generate_issues_analysis(issues, quality_scores))

        # 6. è‡ªåŠ¨ä¿®å¤ä»£ç 
        report_parts.append(self._generate_auto_fix_code(hugo_fix_results))

        # 7. ç›¸ä¼¼åº¦æ£€æµ‹ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if similarity_results:
            report_parts.append(self._generate_similarity_section(similarity_results))

        # 8. æ£€æµ‹ç»Ÿè®¡
        report_parts.append(self._generate_statistics(article_stats, hugo_fix_results))

        return '\n\n'.join(report_parts)

    def _generate_header(self, file_name: str, timestamp: str, file_path: str) -> str:
        """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
        return f"""# ğŸ“Š æ–‡ç« è´¨é‡æ£€æµ‹æŠ¥å‘Š

**æ£€æµ‹æ—¶é—´**: {timestamp}
**æ–‡ç« æ–‡ä»¶**: {file_name}
**æ–‡ç« è·¯å¾„**: {file_path}
**æ£€æµ‹æ ‡å‡†**: Hugoè´¨é‡æ ‡å‡† + SEOä¼˜åŒ–æ£€æµ‹

---"""

    def _generate_summary(self, quality_scores: Dict, hugo_fix_results: Dict, issues: List[Dict], article_stats: Dict) -> str:
        """ç”Ÿæˆæ£€æŸ¥æ€»ç»“"""
        total_score = quality_scores.get('total_score', 0)

        # æ ¹æ®åˆ†æ•°ç¡®å®šè¯„çº§
        if total_score >= 95:
            grade_emoji = "ğŸŒŸ"
            grade_text = "ä¼˜ç§€"
            grade_color = "green"
        elif total_score >= 85:
            grade_emoji = "âœ…"
            grade_text = "è‰¯å¥½"
            grade_color = "blue"
        elif total_score >= 75:
            grade_emoji = "âš ï¸"
            grade_text = "éœ€è¦ä¼˜åŒ–"
            grade_color = "orange"
        else:
            grade_emoji = "âŒ"
            grade_text = "éœ€è¦å¤§å¹…æ”¹è¿›"
            grade_color = "red"

        # ç»Ÿè®¡é—®é¢˜
        critical_issues = len([i for i in issues if i.get('severity') == 'critical'])
        warning_issues = len([i for i in issues if i.get('severity') == 'warning'])
        passed_checks = len([i for i in issues if i.get('status') == 'pass'])

        summary = f"""## ğŸ¯ æœ¬æ¬¡æ£€æŸ¥æ€»ç»“

**æ€»ä½“è¯„åˆ†**: {total_score}/100 {grade_emoji} {grade_text}
**æƒé‡åˆ†é…**: å†…å®¹æ·±åº¦40% + SEOæŠ€æœ¯20% + å†…å®¹ç»“æ„15% + å¯è¯»æ€§10% + åˆè§„æ€§10% + é¢„ç•™5%

### ğŸ“ˆ åˆ†é¡¹å¾—åˆ†"""

        # ç”Ÿæˆå„é¡¹å¾—åˆ†
        dimensions = [
            ('content_depth', 'å†…å®¹æ·±åº¦è´¨é‡', 40),
            ('seo_technical', 'SEOæŠ€æœ¯æŒ‡æ ‡', 20),
            ('content_structure', 'å†…å®¹ç»“æ„å®Œæ•´', 15),
            ('readability', 'å¯è¯»æ€§æŒ‡æ ‡', 10),
            ('adsense_compliance', 'AdSenseåˆè§„æ€§', 10)
        ]

        for dim_key, dim_name, weight in dimensions:
            score = quality_scores.get(dim_key, 0)
            if score >= 90:
                status_emoji = "âœ…"
                status_text = "ä¼˜ç§€"
            elif score >= 80:
                status_emoji = "âœ…"
                status_text = "è‰¯å¥½"
            elif score >= 70:
                status_emoji = "âš ï¸"
                status_text = "ä¸€èˆ¬"
            else:
                status_emoji = "âŒ"
                status_text = "éœ€è¦ä¼˜åŒ–"

            summary += f"\n- {status_emoji} **{dim_name}**: {score}/100 ({status_text}) - æƒé‡{weight}%"

        summary += f"""

### ğŸ“‹ é—®é¢˜ç»Ÿè®¡
- **é€šè¿‡é¡¹ç›®**: {passed_checks}é¡¹
- **ä¸¥é‡é—®é¢˜**: {critical_issues}é¡¹ (å¿…é¡»ä¿®æ”¹)
- **è­¦å‘Šé—®é¢˜**: {warning_issues}é¡¹ (å»ºè®®ä¼˜åŒ–)
- **Hugoæ¨¡æ¿**: {len(hugo_fix_results.get('auto_fixed', []))}é¡¹è‡ªåŠ¨ä¿®å¤ï¼Œ{len(hugo_fix_results.get('needs_manual', []))}é¡¹éœ€ç¡®è®¤"""

        return summary

    def _generate_hugo_fix_section(self, hugo_fix_results: Dict) -> str:
        """ç”ŸæˆHugoæ¨¡æ¿ä¿®å¤éƒ¨åˆ†"""
        auto_fixed = hugo_fix_results.get('auto_fixed', [])
        needs_manual = hugo_fix_results.get('needs_manual', [])
        warnings = hugo_fix_results.get('warnings', [])

        section = """## ğŸ”§ Hugoæ¨¡æ¿è‡ªåŠ¨ä¿®å¤ç»“æœ

> **è¯´æ˜**: Hugoæ¨¡æ¿åˆè§„æ€§ä¸è®¡å…¥è´¨é‡è¯„åˆ†ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨ä¿®å¤ä»¥ä¸‹é—®é¢˜ï¼š"""

        if auto_fixed:
            section += "\n\n### âœ… å·²è‡ªåŠ¨ä¿®å¤"
            for i, fix in enumerate(auto_fixed, 1):
                section += f"\n{i}. {fix}"

        if needs_manual:
            section += "\n\n### âš ï¸ éœ€è¦äººå·¥ç¡®è®¤"
            for i, item in enumerate(needs_manual, 1):
                section += f"\n{i}. {item}"

        if warnings:
            section += "\n\n### ğŸš¨ ä¿®å¤è­¦å‘Š"
            for i, warning in enumerate(warnings, 1):
                section += f"\n{i}. {warning}"

        if not auto_fixed and not needs_manual and not warnings:
            section += "\n\nâœ… Hugoæ¨¡æ¿æ ¼å¼å®Œå…¨ç¬¦åˆæ ‡å‡†ï¼Œæ— éœ€ä¿®å¤ã€‚"

        return section

    def _generate_image_reference_section(self) -> str:
        """ç”Ÿæˆå›¾ç‰‡ä¼˜åŒ–æŒ‡å—å¼•ç”¨éƒ¨åˆ†"""
        return """## ğŸ“· å›¾ç‰‡ä¼˜åŒ–è¯´æ˜

> **âš ï¸ æ£€æµ‹ç³»ç»Ÿå±€é™æ€§è¯´æ˜**
> å½“å‰è´¨é‡æ£€æµ‹å·¥å…·æ— æ³•ç›´æ¥åˆ†æå›¾ç‰‡æ–‡ä»¶è´¨é‡ã€å¤§å°ã€æ ¼å¼ç­‰æŠ€æœ¯æŒ‡æ ‡ã€‚å›¾ç‰‡ç›¸å…³æ£€æµ‹ç»“æœå¯èƒ½ä¸å®Œæ•´ï¼Œéœ€è¦äººå·¥éªŒè¯ã€‚

### ğŸ“‹ ç®€è¦æ£€æŸ¥è¦ç‚¹
- **æ•°é‡è¦æ±‚**: æœ€å°‘3å¼ å›¾ç‰‡ (1å¼ featured_image + 2å¼ inlineå›¾ç‰‡)
- **Altæ–‡æœ¬**: é•¿åº¦50-125å­—ç¬¦ï¼ŒåŒ…å«å…³é”®è¯ï¼Œæè¿°å‡†ç¡®
- **æ–‡ä»¶æ ¼å¼**: ä¼˜å…ˆWebPï¼Œå¤‡é€‰JPEG
- **æ–‡ä»¶å¤§å°**: Featuredå›¾ç‰‡<200KBï¼Œå†…å®¹å›¾ç‰‡<150KB

### ğŸ“– è¯¦ç»†æŒ‡å—æ–‡æ¡£

**å®Œæ•´çš„å›¾ç‰‡ä¼˜åŒ–æ ‡å‡†å’Œæ£€æŸ¥æ¸…å•ï¼Œè¯·å‚è€ƒ:**
ğŸ“„ **[å›¾ç‰‡åˆ†æä¸ä¼˜åŒ–æŒ‡å—](docs/image_analysis_guide.md)**

è¯¥æ–‡æ¡£åŒ…å«ï¼š
- âœ… è¯¦ç»†çš„å›¾ç‰‡è§„æ ¼è¦æ±‚
- âœ… SEOå‹å¥½çš„å‘½åè§„èŒƒ
- âœ… Altæ–‡æœ¬ç¼–å†™æœ€ä½³å®è·µ
- âœ… äººå·¥æ£€æŸ¥æ¸…å•
- âœ… ä¼˜åŒ–å·¥å…·æ¨è
- âœ… æ€§èƒ½ç›‘æµ‹æŒ‡æ ‡

> **å»ºè®®**: åœ¨å‘å¸ƒæ–‡ç« å‰ï¼Œè¯·å¯¹ç…§ç‹¬ç«‹çš„å›¾ç‰‡æŒ‡å—æ–‡æ¡£è¿›è¡Œå®Œæ•´æ£€æŸ¥"""

    def _generate_issues_analysis(self, issues: List[Dict], quality_scores: Dict) -> str:
        """ç”Ÿæˆå…·ä½“é—®é¢˜åˆ†æ"""
        section = "## ğŸ”§ å…·ä½“æ–‡ç« æ”¹åŠ¨å»ºè®®"

        # åˆ†ç±»é—®é¢˜
        critical_issues = [i for i in issues if i.get('severity') == 'critical']
        warning_issues = [i for i in issues if i.get('severity') == 'warning']
        suggestions = [i for i in issues if i.get('severity') == 'suggestion']

        if critical_issues:
            section += "\n\n### ğŸš¨ ä¸¥é‡é—®é¢˜ (å¿…é¡»ä¿®æ”¹)"
            for i, issue in enumerate(critical_issues, 1):
                section += f"\n{i}. **{issue.get('title', 'æœªçŸ¥é—®é¢˜')}**"
                section += f"\n   ```yaml"
                section += f"\n   é—®é¢˜: {issue.get('description', 'æ— æè¿°')}"
                if 'impact' in issue:
                    section += f"\n   å½±å“: {issue['impact']}"
                if 'suggestion' in issue:
                    section += f"\n   ä¿®æ”¹å»ºè®®: {issue['suggestion']}"
                section += f"\n   ```"

        if warning_issues:
            section += "\n\n### âš ï¸ ä¸­ä¼˜å…ˆçº§é—®é¢˜"
            for i, issue in enumerate(warning_issues, 1):
                section += f"\n{i}. **{issue.get('title', 'æœªçŸ¥é—®é¢˜')}**"
                section += f"\n   ```yaml"
                section += f"\n   å½“å‰: {issue.get('current_value', 'æœªçŸ¥')}"
                section += f"\n   å»ºè®®: {issue.get('suggestion', 'æ— å»ºè®®')}"
                section += f"\n   ```"

        if suggestions:
            section += "\n\n### ğŸ’¡ ä¼˜åŒ–å»ºè®®"
            for i, issue in enumerate(suggestions, 1):
                section += f"\n{i}. **{issue.get('title', 'æœªçŸ¥å»ºè®®')}**"
                if 'details' in issue:
                    section += f"\n   - {issue['details']}"

        if not critical_issues and not warning_issues and not suggestions:
            section += "\n\nâœ… æ–‡ç« è´¨é‡è‰¯å¥½ï¼Œæš‚æ— éœ€è¦ä¿®æ”¹çš„é‡è¦é—®é¢˜ã€‚"

        return section



    def _generate_auto_fix_code(self, hugo_fix_results: Dict) -> str:
        """ç”Ÿæˆè‡ªåŠ¨ä¿®å¤ä»£ç """
        if not hugo_fix_results.get('auto_fixed'):
            return ""

        return """## ğŸ“ è‡ªåŠ¨ä¿®å¤ä»£ç 

**å¯ç›´æ¥å¤åˆ¶çš„ä¿®æ”¹å†…å®¹:**

> **æ³¨æ„**: ä»¥ä¸‹ä»£ç åŸºäºæ£€æµ‹ç»“æœè‡ªåŠ¨ç”Ÿæˆï¼Œä½¿ç”¨å‰è¯·ç¡®è®¤å†…å®¹æ­£ç¡®æ€§ã€‚

```yaml
# Front Matterä¿®å¤å»ºè®®
# (è¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å†…å®¹)
---
title: "[å·²è‡ªåŠ¨ä¼˜åŒ–ï¼Œè¯·ç¡®è®¤æ ‡é¢˜å†…å®¹]"
slug: "[å·²è‡ªåŠ¨ç”ŸæˆURLå‹å¥½æ ¼å¼]"
description: "[å·²è‡ªåŠ¨ç”Ÿæˆï¼Œå»ºè®®äººå·¥ä¼˜åŒ–ä¸º150-160å­—ç¬¦]"
date: "[å·²è®¾ç½®ä¸ºISOæ ¼å¼]"
categories: ["[å·²æ ‡å‡†åŒ–ä¸ºè‹±æ–‡åˆ†ç±»]"]
tags: ["[å·²æ ¼å¼åŒ–å’Œå»é‡]"]
author: "Smart Home Team"
draft: false
---
```

**ä¿®å¤è¯´æ˜:**
""" + '\n'.join(f"- {fix}" for fix in hugo_fix_results.get('auto_fixed', []))

    def _generate_similarity_section(self, similarity_results: Dict) -> str:
        """ç”Ÿæˆç›¸ä¼¼åº¦æ£€æµ‹éƒ¨åˆ†"""
        similar_articles = similarity_results.get('similar_articles', [])
        max_similarity = similarity_results.get('max_similarity', 0)

        section = "## ğŸ” ç›¸ä¼¼åº¦æ£€æµ‹ç»“æœ"

        if similar_articles:
            section += f"\n\nâš ï¸ å‘ç° {len(similar_articles)} ç¯‡ç›¸ä¼¼æ–‡ç« ï¼š"
            for i, article in enumerate(similar_articles, 1):
                similarity = article.get('similarity', 0)
                file_name = article.get('file', 'æœªçŸ¥æ–‡ç« ')
                section += f"\n{i}. **{file_name}** - ç›¸ä¼¼åº¦: {similarity:.2%}"

            section += f"\n\n**æœ€é«˜ç›¸ä¼¼åº¦**: {max_similarity:.2%}"
            section += "\n\n**å¤„ç†å»ºè®®**:"
            section += "\n- æ£€æŸ¥å†…å®¹é‡å¤åº¦ï¼Œè€ƒè™‘å¢åŠ å·®å¼‚åŒ–å†…å®¹"
            section += "\n- å¦‚ç¡®è®¤ä¸ºé‡å¤å†…å®¹ï¼Œå»ºè®®åˆ é™¤æˆ–åˆå¹¶"
        else:
            section += "\n\nâœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„æ–‡ç« ã€‚"

        section += f"""

### ğŸ› ï¸ ç‹¬ç«‹ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·

**å¦‚éœ€è¿›è¡Œæ‰¹é‡ç›¸ä¼¼åº¦æ£€æµ‹å’Œé‡å¤æ–‡ç« å¤„ç†ï¼Œè¯·ä½¿ç”¨:**
ğŸ“„ **æ¨¡å—åŒ–ç›¸ä¼¼åº¦æ£€æµ‹ç³»ç»Ÿ**: `similarity-detection/` (æ¨è) æˆ– `scripts/similarity_checker.py` (å…¼å®¹æ€§)

**åŠŸèƒ½ç‰¹ç‚¹:**
- âœ… æ¨¡å—åŒ–æ¶æ„ï¼Œ23ä¸ªç‹¬ç«‹æ¨¡å—ï¼Œæ˜“ç»´æŠ¤æ‰©å±•
- âœ… æ‰¹é‡æ£€æµ‹æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ–‡ç« çš„ç›¸ä¼¼åº¦
- âœ… è‡ªåŠ¨ç§»åŠ¨é‡å¤æ–‡ç« åˆ°duplicate_articlesæ–‡ä»¶å¤¹
- âœ… ç”Ÿæˆè¯¦ç»†çš„ç›¸ä¼¼åº¦åˆ†ææŠ¥å‘Š
- âœ… æ”¯æŒè‡ªå®šä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
- âœ… å‘åå…¼å®¹åŸæœ‰æ¥å£

**ä½¿ç”¨æ–¹æ³•:**
```bash
# ä½¿ç”¨ä»£ç†è„šæœ¬ (æ¨èï¼Œä¿æŒå…¼å®¹æ€§)
python scripts/similarity_checker.py /path/to/articles

# ç›´æ¥ä½¿ç”¨æ¨¡å—åŒ–ç³»ç»Ÿ (é«˜çº§ç”¨æˆ·)
cd similarity-detection && python main.py /path/to/articles

# è‡ªåŠ¨å¤„ç†é‡å¤æ–‡ç« 
python scripts/similarity_checker.py /path/to/articles --auto-process
```"""

        return section

    def _generate_statistics(self, article_stats: Dict, hugo_fix_results: Dict) -> str:
        """ç”Ÿæˆæ£€æµ‹ç»Ÿè®¡"""
        word_count = article_stats.get('word_count', 0)
        check_duration = article_stats.get('check_duration', 0)
        total_rules = article_stats.get('total_rules', 12)

        # é¢„è®¡ä¿®æ”¹æ—¶é—´
        auto_fixes = len(hugo_fix_results.get('auto_fixed', []))
        manual_items = len(hugo_fix_results.get('needs_manual', []))
        estimated_time = manual_items * 5 + max(10, auto_fixes * 2)  # ä¼°ç®—åˆ†é’Ÿ

        return f"""## ğŸ“Š æ£€æµ‹ç»Ÿè®¡

- **æ–‡ç« å­—æ•°**: {word_count:,} å­—
- **æ£€æµ‹æ—¶é•¿**: {check_duration:.1f} ç§’
- **æ£€æµ‹è§„åˆ™**: {total_rules} é¡¹
- **è‡ªåŠ¨ä¿®å¤**: {auto_fixes} é¡¹
- **éœ€è¦ç¡®è®¤**: {manual_items} é¡¹
- **é¢„è®¡ä¿®æ”¹æ—¶é—´**: {estimated_time} åˆ†é’Ÿ

**ä¸‹æ¬¡æ£€æµ‹å»ºè®®**: ä¿®æ”¹å®Œæˆåé‡æ–°è¿è¡Œæ£€æµ‹ä»¥éªŒè¯æ”¹è¿›æ•ˆæœ

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**å·¥å…·ç‰ˆæœ¬**: Hugoæ–‡ç« è´¨é‡æ£€æµ‹å·¥å…· v2.0"""

    def save_report(self, report_content: str, file_path: str, output_dir: str = "reports") -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report_content: æŠ¥å‘Šå†…å®¹
            file_path: åŸæ–‡ç« æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ä¿å­˜çš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        original_name = Path(file_path).stem if file_path else 'article'
        report_filename = f"quality_report_{timestamp}_{original_name}.md"

        # ä¿å­˜æ–‡ä»¶
        report_file_path = output_path / report_filename
        with open(report_file_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        return str(report_file_path)