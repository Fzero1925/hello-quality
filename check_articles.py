#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€é”®æ–‡ç« è´¨é‡æ£€æµ‹è„šæœ¬
æ•´åˆHugoæ¨¡æ¿ä¿®å¤ã€è´¨é‡æ£€æµ‹ã€ç›¸ä¼¼åº¦åˆ†æå’Œä¸­æ–‡æŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import argparse
import shutil
import time
from pathlib import Path
from datetime import datetime
import codecs
import logging
from typing import Dict, List, Optional, Any

# è§£å†³Windowsç¼–ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ¨¡å—
try:
    from modules.hugo_template_fixer import HugoTemplateFixer
    from modules.chinese_reporter import ChineseReporter
    from modules.alt_text_generator import AltTextGenerator
    from modules.tldr_checker import TLDRChecker
    from modules.quality_control.semantic_deduplication import SemanticDeduplicator
    from scripts.quality_check import ComprehensiveQualityChecker
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—éƒ½å­˜åœ¨")
    sys.exit(1)

class ArticleQualityChecker:
    """ä¸€é”®æ–‡ç« è´¨é‡æ£€æµ‹å™¨"""

    def __init__(self, config_path: str = "hugo_quality_standards.yml"):
        """åˆå§‹åŒ–"""
        self.config_path = config_path
        self.start_time = time.time()

        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        try:
            self.template_fixer = HugoTemplateFixer(config_path)
            self.quality_checker = ComprehensiveQualityChecker(pqs_mode=False)
            self.alt_generator = AltTextGenerator(config_path)
            self.tldr_checker = TLDRChecker(config_path)
            self.reporter = ChineseReporter(config_path)
            self.deduplicator = SemanticDeduplicator()
            print("âœ… æ‰€æœ‰æ£€æµ‹æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
            sys.exit(1)

    def check_single_article(self, file_path: str, auto_fix: bool = True, save_changes: bool = False) -> Dict:
        """æ£€æŸ¥å•ç¯‡æ–‡ç« 

        Args:
            file_path: æ–‡ç« æ–‡ä»¶è·¯å¾„
            auto_fix: æ˜¯å¦è‡ªåŠ¨ä¿®å¤Hugoæ¨¡æ¿é—®é¢˜
            save_changes: æ˜¯å¦ä¿å­˜ä¿®æ”¹åçš„æ–‡ç« 

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        print(f"\nğŸ” æ­£åœ¨æ£€æµ‹æ–‡ç« : {file_path}")

        # è¯»å–æ–‡ç« å†…å®¹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
        except Exception as e:
            return {'error': f"æ— æ³•è¯»å–æ–‡ä»¶: {e}"}

        # 1. Hugoæ¨¡æ¿ä¿®å¤
        hugo_fix_results = {}
        fixed_content = original_content
        if auto_fix:
            print("  ğŸ“ æ­£åœ¨ä¿®å¤Hugoæ¨¡æ¿...")
            fixed_content, hugo_fix_results = self.template_fixer.fix_article(original_content, file_path)

            if save_changes and fixed_content != original_content:
                # ä¿å­˜ä¿®å¤åçš„æ–‡ç« 
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(fixed_content)
                    print(f"  âœ… å·²ä¿å­˜ä¿®å¤åçš„æ–‡ç« ")
                except Exception as e:
                    print(f"  âš ï¸ ä¿å­˜å¤±è´¥: {e}")

        # 2. Altæ–‡æœ¬åˆ†æ
        print("  ğŸ–¼ï¸ æ­£åœ¨åˆ†æå›¾ç‰‡Altæ–‡æœ¬...")
        # æå–Front Matteræ•°æ®ç”¨äºAltåˆ†æ
        try:
            front_matter_data = self._extract_front_matter_data(fixed_content)
        except Exception as e:
            print(f"  âš ï¸ Front Matterè§£æå¤±è´¥: {e}")
            front_matter_data = {}

        alt_analysis_results = self.alt_generator.analyze_images(
            fixed_content, front_matter_data, file_path
        )

        # 3. TL;DRæ£€æµ‹
        print("  ğŸ“‹ æ­£åœ¨æ£€æµ‹TL;DRç»“æ„...")
        tldr_results = self.tldr_checker.check_tldr(fixed_content)

        # 4. è´¨é‡æ£€æµ‹
        print("  ğŸ“Š æ­£åœ¨æ‰§è¡Œè´¨é‡æ£€æµ‹...")
        quality_results = self.quality_checker.check_article_quality(file_path)

        # 5. ç›¸ä¼¼åº¦æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼Œæ¨èä½¿ç”¨ç‹¬ç«‹å·¥å…·ï¼‰
        print("  ğŸ” æ­£åœ¨è¿›è¡Œç®€å•ç›¸ä¼¼åº¦æ£€æµ‹...")
        similarity_results = {}
        try:
            # ç®€åŒ–çš„ç›¸ä¼¼åº¦æ£€æµ‹ï¼Œä¸»è¦ç”¨äºå•æ–‡ç« åˆ†æ
            # å¯¹äºæ‰¹é‡ç›¸ä¼¼åº¦æ£€æµ‹ï¼Œæ¨èä½¿ç”¨æ¨¡å—åŒ–ç›¸ä¼¼åº¦æ£€æµ‹ç³»ç»Ÿæˆ–ä»£ç†è„šæœ¬

            # æå–æ–‡ç« å…ƒæ•°æ®
            metadata = {
                'title': front_matter_data.get('title', ''),
                'date': front_matter_data.get('date', ''),
                'file_path': file_path
            }

            # ä½¿ç”¨è¯­ä¹‰å»é‡å™¨è¿›è¡Œç®€å•æ£€æµ‹
            is_similar, similarity_data = self.deduplicator.check_content_similarity(fixed_content, metadata)
            similarity_results = {
                'is_similar': is_similar,
                'similar_articles': similarity_data.get('similarities', [])[:3],  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                'max_similarity': similarity_data.get('max_similarity', 0.0),
                'use_independent_tool': True  # æ ‡è®°æ¨èä½¿ç”¨ç‹¬ç«‹å·¥å…·
            }

            if is_similar:
                print(f"  âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„ç›¸ä¼¼æ–‡ç« ï¼Œæœ€é«˜ç›¸ä¼¼åº¦: {similarity_results['max_similarity']:.3f}")
                print(f"  ğŸ’¡ å»ºè®®ä½¿ç”¨æ¨¡å—åŒ–ç³»ç»Ÿè¿›è¡Œè¯¦ç»†åˆ†æ: python scripts/similarity_checker.py")
            else:
                print("  âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾ç›¸ä¼¼æ–‡ç« ")

        except Exception as e:
            print(f"  âš ï¸ ç›¸ä¼¼åº¦æ£€æµ‹å¤±è´¥: {e}")
            similarity_results = {
                'error': str(e),
                'use_independent_tool': True
            }

        # 6. ç»Ÿè®¡ä¿¡æ¯
        article_stats = self._calculate_stats(fixed_content, file_path)

        return {
            'file_path': file_path,
            'original_content': original_content,
            'fixed_content': fixed_content,
            'hugo_fix_results': hugo_fix_results,
            'alt_analysis_results': alt_analysis_results,
            'tldr_results': tldr_results,
            'quality_results': quality_results,
            'similarity_results': similarity_results,
            'article_stats': article_stats,
            'check_duration': time.time() - self.start_time
        }

    def check_directory(self, directory: str, pattern: str = "*.md", auto_fix: bool = True) -> List[Dict]:
        """æ£€æŸ¥ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ç« 

        Args:
            directory: ç›®å½•è·¯å¾„
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
            auto_fix: æ˜¯å¦è‡ªåŠ¨ä¿®å¤

        Returns:
            æ‰€æœ‰æ–‡ç« çš„æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        dir_path = Path(directory)
        if not dir_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
            return []

        # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
        md_files = list(dir_path.glob(pattern))
        if not md_files:
            print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶: {pattern}")
            return []

        print(f"ğŸ“ æ‰¾åˆ° {len(md_files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æ£€æµ‹...")

        results = []
        for i, file_path in enumerate(md_files, 1):
            print(f"\n[{i}/{len(md_files)}] å¤„ç†æ–‡ä»¶: {file_path.name}")
            try:
                result = self.check_single_article(str(file_path), auto_fix)
                results.append(result)
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
                results.append({
                    'file_path': str(file_path),
                    'error': str(e)
                })

        return results


    def generate_report(self, result: Dict, output_dir: str = "reports") -> str:
        """ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š

        Args:
            result: æ£€æµ‹ç»“æœ
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if 'error' in result:
            return ""

        print("  ğŸ“„ æ­£åœ¨ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š...")

        # æå–æŠ¥å‘Šæ‰€éœ€çš„æ•°æ®
        quality_scores = self._extract_quality_scores(result['quality_results'])
        issues = self._extract_issues(result['quality_results'])

        # ç”ŸæˆæŠ¥å‘Šï¼ˆä½¿ç”¨æ–°çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰
        report_content = self.reporter.generate_report(
            file_path=result['file_path'],
            quality_scores=quality_scores,
            hugo_fix_results=result['hugo_fix_results'],
            issues=issues,
            article_stats=result['article_stats'],
            similarity_results=result['similarity_results']
        )

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.reporter.save_report(
            report_content,
            result['file_path'],
            output_dir
        )

        return report_file

    def _calculate_stats(self, content: str, file_path: str) -> Dict:
        """è®¡ç®—æ–‡ç« ç»Ÿè®¡ä¿¡æ¯"""
        # ç§»é™¤Front Matter
        if content.startswith('---'):
            end_index = content.find('\n---', 3)
            if end_index != -1:
                article_content = content[end_index + 4:]
            else:
                article_content = content
        else:
            article_content = content

        # è®¡ç®—å­—æ•°ï¼ˆä¸­æ–‡æŒ‰å­—ç¬¦è®¡ç®—ï¼Œè‹±æ–‡æŒ‰å•è¯è®¡ç®—ï¼‰
        chinese_chars = len([c for c in article_content if '\u4e00' <= c <= '\u9fff'])
        english_words = len([w for w in article_content.split() if any(c.isalpha() for c in w)])
        word_count = chinese_chars + english_words

        return {
            'word_count': word_count,
            'char_count': len(article_content),
            'check_duration': time.time() - self.start_time,
            'total_rules': 12,
            'file_size': Path(file_path).stat().st_size if Path(file_path).exists() else 0
        }

    def _extract_quality_scores(self, quality_results: Dict) -> Dict:
        """ä»è´¨é‡æ£€æµ‹ç»“æœä¸­æå–è¯„åˆ†"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„quality_checkerè¿”å›æ ¼å¼è°ƒæ•´
        return {
            'total_score': quality_results.get('total_score', 75),
            'content_depth': quality_results.get('content_depth', 80),
            'seo_technical': quality_results.get('seo_technical', 75),
            'content_structure': quality_results.get('content_structure', 85),
            'readability': quality_results.get('readability', 80),
            'adsense_compliance': quality_results.get('adsense_compliance', 90)
        }

    def _extract_issues(self, quality_results: Dict) -> List[Dict]:
        """ä»è´¨é‡æ£€æµ‹ç»“æœä¸­æå–é—®é¢˜åˆ—è¡¨"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„quality_checkerè¿”å›æ ¼å¼è°ƒæ•´
        issues = []

        # ç¤ºä¾‹é—®é¢˜æå–é€»è¾‘
        if quality_results.get('seo_issues'):
            for issue in quality_results['seo_issues']:
                issues.append({
                    'title': issue.get('title', 'æœªçŸ¥é—®é¢˜'),
                    'severity': 'warning',
                    'description': issue.get('description', ''),
                    'suggestion': issue.get('suggestion', '')
                })

        return issues

    def _extract_front_matter_data(self, content: str) -> Dict:
        """æå–Front Matteræ•°æ®"""
        try:
            import yaml

            if not content.startswith('---'):
                return {}

            end_index = content.find('\n---', 3)
            if end_index == -1:
                return {}

            front_matter_text = content[3:end_index]
            return yaml.safe_load(front_matter_text) or {}
        except Exception:
            return {}

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Hugoæ–‡ç« è´¨é‡æ£€æµ‹å·¥å…·')
    parser.add_argument('path', nargs='?', default='D:/Users/Fzero/project/ai-smarthome/content-generation-tool/articles',
                       help='è¦æ£€æµ‹çš„æ–‡ç« æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--config', default='hugo_quality_standards.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default='reports',
                       help='æŠ¥å‘Šè¾“å‡ºç›®å½•')
    parser.add_argument('--no-auto-fix', action='store_true',
                       help='ç¦ç”¨è‡ªåŠ¨ä¿®å¤Hugoæ¨¡æ¿')
    parser.add_argument('--save-changes', action='store_true',
                       help='ä¿å­˜ä¿®å¤åçš„æ–‡ç« åˆ°åŸæ–‡ä»¶')

    args = parser.parse_args()

    print("ğŸš€ Hugoæ–‡ç« è´¨é‡æ£€æµ‹å·¥å…· v2.1")
    print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {args.path}")
    print(f"âš™ï¸ é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤: {'å¯ç”¨' if not args.no_auto_fix else 'ç¦ç”¨'}")
    print(f"ğŸ’¾ ä¿å­˜ä¿®æ”¹: {'æ˜¯' if args.save_changes else 'å¦'}")
    print("-" * 50)

    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    path = Path(args.path)
    if not path.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {args.path}")
        return 1

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    try:
        checker = ArticleQualityChecker(args.config)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1

    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    Path(args.output_dir).mkdir(exist_ok=True)

    start_time = time.time()

    # æ‰§è¡Œæ£€æµ‹
    if path.is_file():
        # å•æ–‡ä»¶æ£€æµ‹
        result = checker.check_single_article(
            str(path),
            auto_fix=not args.no_auto_fix,
            save_changes=args.save_changes
        )

        if 'error' not in result:
            # ç”ŸæˆæŠ¥å‘Š
            report_file = checker.generate_report(result, args.output_dir)
            if report_file:
                print(f"\nğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

            # ç›¸ä¼¼åº¦æ£€æµ‹æç¤º
            if result.get('similarity_results', {}).get('is_similar'):
                print(f"\nğŸ’¡ æ£€æµ‹åˆ°ç›¸ä¼¼æ–‡ç« ï¼Œå»ºè®®ä½¿ç”¨æ¨¡å—åŒ–ç³»ç»Ÿè¿›è¡Œè¯¦ç»†åˆ†æ:")
                print(f"   python scripts/similarity_checker.py \"{path.parent}\" --auto-process")
                print(f"   æˆ–ç›´æ¥ä½¿ç”¨: cd similarity-detection && python main.py \"{path.parent}\" --auto-process")
        else:
            print(f"âŒ æ£€æµ‹å¤±è´¥: {result['error']}")
            return 1

    else:
        # ç›®å½•æ£€æµ‹
        results = checker.check_directory(
            str(path),
            auto_fix=not args.no_auto_fix
        )

        if not results:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ç« ")
            return 1

        # å¤„ç†ç»“æœ
        successful_results = [r for r in results if 'error' not in r]
        failed_results = [r for r in results if 'error' in r]

        print(f"\nğŸ“Š æ£€æµ‹å®Œæˆ: æˆåŠŸ {len(successful_results)} ç¯‡ï¼Œå¤±è´¥ {len(failed_results)} ç¯‡")

        # ç”ŸæˆæŠ¥å‘Š
        report_files = []
        similar_articles_detected = 0

        for result in successful_results:
            # ç”ŸæˆæŠ¥å‘Š
            report_file = checker.generate_report(result, args.output_dir)
            if report_file:
                report_files.append(report_file)

            # ç»Ÿè®¡ç›¸ä¼¼æ–‡ç« 
            if result.get('similarity_results', {}).get('is_similar'):
                similar_articles_detected += 1

        if report_files:
            print(f"\nğŸ“„ å…±ç”Ÿæˆ {len(report_files)} ä»½æŠ¥å‘Š:")
            for report_file in report_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {Path(report_file).name}")
            if len(report_files) > 5:
                print(f"   ... å’Œå…¶ä»– {len(report_files) - 5} ä»½æŠ¥å‘Š")

        # ç›¸ä¼¼åº¦æ£€æµ‹å»ºè®®
        if similar_articles_detected > 0:
            print(f"\nğŸ” æ£€æµ‹åˆ° {similar_articles_detected} ç¯‡æ–‡ç« å¯èƒ½å­˜åœ¨ç›¸ä¼¼å†…å®¹")
            print(f"ğŸ’¡ å»ºè®®ä½¿ç”¨æ¨¡å—åŒ–ç›¸ä¼¼åº¦æ£€æµ‹ç³»ç»Ÿè¿›è¡Œæ‰¹é‡åˆ†æ:")
            print(f"   python scripts/similarity_checker.py \"{path}\" --auto-process")
            print(f"   æˆ–ç›´æ¥ä½¿ç”¨: cd similarity-detection && python main.py \"{path}\" --auto-process")

    # æ˜¾ç¤ºæ€»è€—æ—¶
    total_time = time.time() - start_time
    print(f"\nâ±ï¸ æ€»æ£€æµ‹æ—¶é—´: {total_time:.1f} ç§’")
    print("âœ… æ£€æµ‹å®Œæˆï¼")

    # åŠŸèƒ½æç¤º
    print(f"\nğŸ› ï¸ å¯ç”¨çš„ç‹¬ç«‹å·¥å…·:")
    print(f"   ğŸ“Š ç›¸ä¼¼åº¦æ£€æµ‹: python scripts/similarity_checker.py (æ¨¡å—åŒ–v2.0)")
    print(f"   ğŸ§© ç›´æ¥ä½¿ç”¨æ¨¡å—åŒ–: cd similarity-detection && python main.py")
    print(f"   ğŸ“– å›¾ç‰‡åˆ†ææŒ‡å—: docs/image_analysis_guide.md")

    return 0

if __name__ == '__main__':
    sys.exit(main())